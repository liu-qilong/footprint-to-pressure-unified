train_script: 'BasicTrainScript'
device_select: 'auto'
use_pretrain: False
dataset:
  name: 'Footprint2Pressure_Blend_SensorStack'
  train_ratio: 0.8
  args:
    footprint_wrap_folder: 'data/processed/footprint-wrap/'
    pedar_dynamic_path: 'data/processed/pedar_dynamic.pkl'
    sense_range: 600
    stack_range: 50
    img_size: 1
dataloader:
  name: 'DataLoader'
  args:
    batch_size: 32
    shuffle: True
model:
  name: 'MLP_cos_emb'
  args:
    img_size: 1
    pos_emb_len: 512
    young_emb_len: 128
    hidden: 2048
loss:
  name: 'MSELoss'
  args: {}
metric:
  MAE:
    name: 'L1Loss'
    args: {}
  MSE:
    name: 'MSELoss'
    args: {}
optimizer: 
  name: 'SGD'
  epochs: 50
  args:
    lr: 0.1

# Setting a batch size of 32 doesn't work because the data samples are far too similar. The model is still likely to output the mean value. See experiment/mlp-0620/ for fixing.
# -- 24 Sep 2024